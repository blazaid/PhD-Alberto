{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuras que uso a lo largo de la tesis, para que los estilos sean coherentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.mlab import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import fuzzle.lvars\n",
    "import fuzzle.mfs\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, accuracy_score\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from pynsia.tensorflow import fuzzy as tfz\n",
    "from pynsia.pointcloud import PointCloud\n",
    "from thesis_plots import plot_confusion_matrix\n",
    "\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pongo aquí las configuraciones por defecto de tipos de letra, tamaños, colores, etcétera. Estaría muy bien hacer una plantilla más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('legend', **{\n",
    "    'fontsize': '10',\n",
    "})\n",
    "matplotlib.rc('lines', **{\n",
    "    'linewidth': '1',\n",
    "})\n",
    "CMAP = plt.cm.Purples_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de las figuras para que los estilos de la tesis sean más o menos homogéneos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUARED_2 = 3, 3  # .45\\textwidth\n",
    "SQUARED_M = 3.75, 3.75  # \\texwidth, para marginfigure\n",
    "WIDE_1 = 8, 3  # \\textwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS = {'edgar': '$S_1$', 'jj': '$S_2$', 'miguel': '$S_3$'}\n",
    "SUBJECTS_WITH_ALL = {'all': '$S_A$', 'edgar': '$S_1$', 'jj': '$S_2$', 'miguel': '$S_3$'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edad de los conductores por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Edades':['15-17','18-20','21-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64','65-69','70-74','74+',],\n",
    "    'Hombres':[39341,318037,729846,1097874,1472038,1828905,1768957,1688069,1460193,1256212,1082591,974768,709285,1190514],\n",
    "    'Mujeres':[15697,238534,651961,1054377,1337432,1568926,1445740,1321330,1055472,810168,569461,387158,189829,1138945],\n",
    "})\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "df.plot(kind='bar', ax=ax)\n",
    "ax.set_xticklabels(df['Edades'])\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/drivers-ages-per-genre.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estado de la cuestión - Inteligencia computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rise of deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l(x, a, b, c, k, m, v, q):\n",
    "    return a + (k - a)/ np.power((c + q * np.exp(-b * (x - m))), 1 / v)\n",
    "\n",
    "\n",
    "x = np.arange(0.75, 2, 0.001)\n",
    "y1 = l(x, 0, 5, 0.1, 1, 1, 1, 1)\n",
    "y2 = l(x, 0, 4.5, 0.15, 1, 1, 1, 1)\n",
    "y3 = l(x, 0, 4, 0.25, 1, 1, 1, 1)\n",
    "y4 = l(x, 0, 3.5, 0.5, 1, 1, 1, 1)\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_M)\n",
    "ax.set_ylim((-1, 10))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, y1, label=\"Deep learning\")\n",
    "ax.plot(x, y2, label=\"Deeper networks\")\n",
    "ax.plot(x, y3, label=\"Shallow networks\")\n",
    "ax.plot(x, y4, label=\"Traditional CI\")\n",
    "ax.legend(loc=\"best\");\n",
    "ax.set_ylabel('Performance')\n",
    "ax.set_xlabel('Amount of data')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "fig.savefig('thesis-figures/deep-learning-capabilities.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación. Sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1+np.e**(-x))\n",
    "\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "y = sigmoid(x)\n",
    "dx = y * (1 - y)\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, y, label=\"$\\sigma(x)$\")\n",
    "ax.plot(x, dx, label=\"$\\\\frac{\\partial \\sigma(x)}{\\partial x}$\")\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/sigmoid-function.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación. Tangente hiperbólica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return 1./(1 + np.e ** (-x))\n",
    "\n",
    "x = np.arange(-5, 5, 0.01)\n",
    "y = np.tanh(x)\n",
    "dx = 1 - y ** 2\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_ylim((-1.1, 1.1))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, y, label=\"$tanh(x)$\")\n",
    "ax.plot(x, dx, label=\"$\\\\frac{\\partial tanh(x)}{\\partial x}$\")\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/tanh-function.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación. ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.arange(-1, 2, 0.01)\n",
    "y = relu(x)\n",
    "dx = [0 if r <= 0 else 1 for r in x]\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_ylim((-0.1, 1.5))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, y, label=\"$ReLU(x)$\")\n",
    "ax.plot(x, dx, label=\"$\\\\frac{\\partial ReLU(x)}{\\partial x}$\")\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/relu-function.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación. Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak = 0.1\n",
    "def leaky_relu(x):\n",
    "    return np.maximum(leak * x, x)\n",
    "\n",
    "x = np.arange(-1, 2, 0.01)\n",
    "y = leaky_relu(x)\n",
    "dx = [leak if r <= 0 else 1 for r in x]\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_ylim((-0.1, 1.5))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, y, label=\"$LReLU(x, 0.1)$\")\n",
    "ax.plot(x, dx, label=\"$\\\\frac{\\partial L-ReLU(x, 0.1)}{\\partial x}$\")\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/leaky-relu-function.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pertenencia. Trangular y trapezoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, Δb, Δc, Δd):\n",
    "    line_asc = (x - a) / Δb\n",
    "    line_des = (a + Δb + Δc - x) / Δd + 1\n",
    "    union = min(line_asc, line_des)\n",
    "    return min(max(union, 0), 1)\n",
    "\n",
    "x = np.arange(-4, 7, 0.01)\n",
    "trimf = [f(e, -3, 2, 0, 1) for e in x]\n",
    "trapmf = [f(e, 1, 1, 3, 1) for e in x]\n",
    "\n",
    "# Setup centered axes\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_M)\n",
    "ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "# Create and show plot\n",
    "ax.plot(x, trimf, label=\"triangular($-3, -1, 0$)\")\n",
    "ax.plot(x, trapmf, label=\"trapezoidal($1, 2, 5, 6$)\")\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/trimf-trapmf.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-normas. Mínimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "X = np.arange(0, 1, 0.05)\n",
    "Y = np.arange(0, 1, 0.05)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = np.minimum(X, Y)\n",
    "\n",
    "fig = plt.figure(figsize=SQUARED_2)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlim(1, 0)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_zlim(0, 1)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "fig.savefig('thesis-figures/tnorm-minimum.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-normas. Producto algebráico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "X = np.arange(0, 1, 0.05)\n",
    "Y = np.arange(0, 1, 0.05)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = X * Y\n",
    "\n",
    "fig = plt.figure(figsize=SQUARED_2)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlim(1, 0)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_zlim(0, 1)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "fig.savefig('thesis-figures/tnorm-algebraic-product.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-conormas. Maximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "X = np.arange(0, 1, 0.05)\n",
    "Y = np.arange(0, 1, 0.05)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = np.maximum(X, Y)\n",
    "\n",
    "fig = plt.figure(figsize=SQUARED_2)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlim(1, 0)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_zlim(0, 1)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "fig.savefig('thesis-figures/snorm-maximum.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-conormas. Suma algebráica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "X = np.arange(0, 1, 0.05)\n",
    "Y = np.arange(0, 1, 0.05)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = X + Y - X * Y\n",
    "\n",
    "fig = plt.figure(figsize=SQUARED_2)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlim(1, 0)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_zlim(0, 1)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "fig.savefig('thesis-figures/snorm-probabilistic-sum.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estado de la cuestión - Simulación de tráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ningún gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estado de la cuestión - Modelos de comportamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ningún gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de comportamiento - Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ningún gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfiles de aceleración en los conjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cf-all-training.csv', index_col=None)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDE_1[0], WIDE_1[1]))\n",
    "ax.set_ylim(-0.35, 0.35)\n",
    "df['Acceleration'].plot(ax=ax, label=\"Acceleration ($m/s^2$)\");\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/acceleration-profiles-training.pdf',bbox_inches='tight')\n",
    "\n",
    "df = pd.read_csv('data/cf-all-validation.csv', index_col=None)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(WIDE_1[0], WIDE_1[1]))\n",
    "ax.set_ylim(-0.35, 0.35)\n",
    "df['Acceleration'].plot(ax=ax, label=\"Acceleration ($m/s^2$)\");\n",
    "ax.legend(loc=\"best\");\n",
    "fig.savefig('thesis-figures/acceleration-profiles-test.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de comportamiento - Modelo longitudinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para todos los resultados que van en función de los epochs, el eje $X$ se ha limitado a 100. Todas las salidas se han ajustado a este criterio independientemente del número de epochs que haya requerido su entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_X_LIM = (0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlador difuso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los patrones de los ficheros que tienen los valores de las salidas y los RMS son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fcs_rms_f_pat = 'final-outputs/cf-fcs-rms-all-*.csv'\n",
    "lm_fcs_out_f_pat = 'final-outputs/cf-fcs-outputs-all-*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fcs_rms_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_fcs_rms_f_pat), key=lambda x: (len(x), x))\n",
    "]\n",
    "lm_fcs_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_fcs_out_f_pat), key=lambda x: (len(x), x))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, sacamos los nombres de las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fcs_architectures = {\n",
    "    s.replace('.csv', '').replace(lm_fcs_rms_f_pat[:-5], ''): '$FCS_{}$'.format(i)\n",
    "    for i, s in enumerate(sorted(glob.glob(lm_fcs_rms_f_pat), key=lambda x: (len(x), x)), start=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'architecture':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "    'topology': [],\n",
    "}\n",
    "for i, (architecture, df) in enumerate(zip(lm_fcs_architectures, lm_fcs_rms_dfs)):\n",
    "    table['architecture'].append(lm_fcs_architectures[architecture])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "    table['topology'].append(architecture)\n",
    "df = pd.DataFrame(table, index=None)[['architecture', 'training', 'validation', 'test', 'topology']]\n",
    "df.set_index('architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE en training, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.058, 0.1)\n",
    "stage_df = pd.DataFrame()\n",
    "lines_training = []\n",
    "lines_validation = []\n",
    "for i, (architecture, df) in enumerate(zip(lm_fcs_architectures, lm_fcs_rms_dfs)):\n",
    "    lines_training += ax.plot(df['training'], label=lm_fcs_architectures[architecture], color='C{}'.format(i))\n",
    "    lines_validation += ax.plot(df['validation'], color='C{}'.format(i), alpha=0.3)\n",
    "ax.legend(handles=lines_training, loc=2)\n",
    "fig.savefig('thesis-figures/lm-fcs-rmse-all-training-and-validation-detail.pdf', bbox_inches='tight')\n",
    "\n",
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.053, 0.12)\n",
    "for i, (architecture, df) in enumerate(zip(lm_fcs_architectures, lm_fcs_rms_dfs)):\n",
    "    lines_training += ax.plot(df['test'], label=lm_fcs_architectures[architecture], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels(), loc=2)\n",
    "fig.savefig('thesis-figures/lm-fcs-rmse-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particiones difusas de las variables lingüísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fcs_arch = '2-2-2-2-2-2-2'\n",
    "\n",
    "lm_fcs_df = pd.read_csv('final-outputs/cf-fcs-description-all-{}.csv'.format(best_fcs_arch), index_col=None)\n",
    "\n",
    "VARIABLES = [\n",
    "    ('Leader distance', 'LeaderDistance', (0, 1)), ('Next TLS distance', 'NextTLSDistance', (0, 1)),\n",
    "    ('Next TLS green', 'NextTLSGreen', (0, 1)), ('Next TLS yellow', 'NextTLSYellow', (0, 1)),\n",
    "    ('Next TLS red', 'NextTLSRed', (0, 1)), ('Speed', 'Speed', (0, 20)),\n",
    "    ('Speed to leader', 'SpeedToLeader', (-40, 40)),\n",
    "]\n",
    "\n",
    "first_row = lm_fcs_df.iloc[0]\n",
    "last_row = lm_fcs_df.iloc[-1]\n",
    "lvars = [[], []]\n",
    "for var_index, current_row in enumerate([first_row, last_row]):\n",
    "    vars_values = [\n",
    "        {k.split('/')[-1]: v for k, v in current_row.items() if k.startswith('tfz/var/' + variable + '/')}\n",
    "        for _, variable, _ in VARIABLES\n",
    "    ]\n",
    "    for var_description, (variable_name, variable, domain) in zip(vars_values, VARIABLES):\n",
    "        for k, v in var_description.items():\n",
    "            var_description[k] = np.abs(v)\n",
    "        base = var_description['b']\n",
    "        next_starting_point = base + var_description['s0']\n",
    "        num_fs = ((len(var_description) - 1) // 2) + 1\n",
    "\n",
    "        lvar = fuzzle.lvars.InputLVar(variable_name, domain)\n",
    "        for i in range(num_fs):\n",
    "            if i == 0:\n",
    "                b = next_starting_point + var_description['s1']\n",
    "                mf = fuzzle.mfs.LineDescMF(next_starting_point, b)\n",
    "            elif i == num_fs - 1:\n",
    "                last = len(var_description) - 2           \n",
    "                b = next_starting_point + var_description['s{}'.format(last)]\n",
    "                mf = fuzzle.mfs.LineAscMF(next_starting_point, b)\n",
    "            else:\n",
    "                sta = ['s' + str(j) for j in range(i * 2 - 1, i * 2 + 2)]\n",
    "                b = next_starting_point + var_description[sta[0]]\n",
    "                c = b + var_description[sta[1]]\n",
    "                d = c + var_description[sta[2]]\n",
    "                mf = fuzzle.mfs.TrapMF(next_starting_point, b, c, d)\n",
    "                next_starting_point = c\n",
    "\n",
    "            lvar['f{}'.format(i)] = mf\n",
    "        lvars[var_index].append(lvar)\n",
    "\n",
    "for var1, var2 in zip(lvars[0], lvars[1]):\n",
    "    if var1.name not in ('Next TLS green', 'Next TLS yellow', 'Next TLS red'):\n",
    "        mf_names = [fs for fs in var1]\n",
    "        X = np.linspace(*var1.domain, 1000)\n",
    "        Y1 = np.array([\n",
    "            [var1[mf_name](x) for mf_name in mf_names]\n",
    "            for x in X\n",
    "        ])\n",
    "        Y2 = np.array([\n",
    "            [var2[mf_name](x) for mf_name in mf_names]\n",
    "            for x in X\n",
    "        ])\n",
    "        X = np.reshape(X, (-1, 1))\n",
    "\n",
    "        # Plot the mfs\n",
    "        fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "        for i, (column1, column2, label) in enumerate(zip(Y1.T, Y2.T, mf_names)):\n",
    "            ax.plot(X[:,0], column1, alpha=0.2, linewidth=5, color='C' + str(i));\n",
    "            ax.plot(X[:,0], column2, alpha=1, label=label, color='C' + str(i));\n",
    "        ax.legend(loc='best');\n",
    "        var_name = var1.name.lower().replace(' ', '-').replace('(', '').replace(')', '').replace(',', '')\n",
    "        fig.savefig('thesis-figures/lm-fcs-best-architecture-{}-variable-partition.pdf'.format(var_name), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximación al conjunto de test por las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximación al conjunto de error\n",
    "lm_fcs_outs_df = pd.DataFrame()\n",
    "for architecture, df in zip(lm_fcs_architectures, lm_fcs_out_dfs):\n",
    "    lm_fcs_outs_df[lm_fcs_architectures[architecture]] = df['real']\n",
    "# General\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "ax.set_xlim(0, 1650)\n",
    "ax.set_ylim(-0.2, 0.2)\n",
    "lm_fcs_outs_df.plot(ax=ax);\n",
    "ax.plot(lm_fcs_out_dfs[0]['expected'], alpha=0.3, linewidth=1, label='expected');\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-fcs-outs-all-test-comparison.pdf', bbox_inches='tight')\n",
    "\n",
    "# Detail\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "#ax.set_xlim(300, 550)\n",
    "ax.set_xlim(750, 1050)\n",
    "ax.set_ylim(-0.15, 0.15)\n",
    "lm_fcs_outs_df.plot(ax=ax);\n",
    "ax.plot(lm_fcs_out_dfs[0]['expected'], alpha=0.3, linewidth=1, label='expected');\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-fcs-outs-all-test-comparison-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los patrones de los ficheros que tienen los valores de las salidas y los RMS son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mlp_rms_f_pat = 'final-outputs/cf-mlp-rms-all-*.csv'\n",
    "lm_mlp_out_f_pat = 'final-outputs/cf-mlp-outputs-all-*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mlp_rms_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_mlp_rms_f_pat), key=lambda x: (len(x), x))\n",
    "]\n",
    "lm_mlp_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_mlp_out_f_pat), key=lambda x: (len(x), x))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, sacamos los nombres de las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mlp_architectures = {\n",
    "    s.replace('.csv', '').replace(lm_mlp_rms_f_pat[:-5], ''): '$MLP_{}$'.format(i)\n",
    "    for i, s in enumerate(sorted(glob.glob(lm_mlp_rms_f_pat), key=lambda x: (len(x), x)), start=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'architecture':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "    'topology': []\n",
    "}\n",
    "for i, (architecture, df) in enumerate(zip(lm_mlp_architectures, lm_mlp_rms_dfs)):\n",
    "    table['architecture'].append(lm_mlp_architectures[architecture])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "    table['topology'].append(architecture)\n",
    "df = pd.DataFrame(table, index=None)[['architecture', 'training', 'validation', 'test', 'topology']]\n",
    "df.set_index('architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE en training, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.04, 0.065)\n",
    "stage_df = pd.DataFrame()\n",
    "lines_training = []\n",
    "lines_validation = []\n",
    "for i, (architecture, df) in enumerate(zip(lm_mlp_architectures, lm_mlp_rms_dfs)):\n",
    "    lines_training += ax.plot(df['training'], label=lm_mlp_architectures[architecture], color='C{}'.format(i))\n",
    "    lines_validation += ax.plot(df['validation'], color='C{}'.format(i), alpha=0.3)\n",
    "ax.legend(handles=lines_training, loc=3)\n",
    "fig.savefig('thesis-figures/lm-mlp-rmse-all-training-and-validation-detail.pdf', bbox_inches='tight')\n",
    "\n",
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.053, 0.064)\n",
    "for i, (architecture, df) in enumerate(zip(lm_mlp_architectures, lm_mlp_rms_dfs)):\n",
    "    lines_training += ax.plot(df['test'], label=lm_mlp_architectures[architecture], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels(), loc=3)\n",
    "fig.savefig('thesis-figures/lm-mlp-rmse-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximación al conjunto de test por las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximación al conjunto de error\n",
    "lm_mlp_outs_df = pd.DataFrame()\n",
    "for architecture, df in zip(lm_mlp_architectures, lm_mlp_out_dfs):\n",
    "    lm_mlp_outs_df[lm_mlp_architectures[architecture]] = df['real']\n",
    "# General\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "ax.set_xlim(0, 1650)\n",
    "ax.set_ylim(-0.2, 0.2)\n",
    "lm_mlp_outs_df.plot(ax=ax);\n",
    "ax.plot(lm_mlp_out_dfs[0]['expected'], alpha=0.3, linewidth=1, label='expected');\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-mlp-outs-all-test-comparison.pdf', bbox_inches='tight')\n",
    "\n",
    "# Detail\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "#ax.set_xlim(300, 550)\n",
    "ax.set_xlim(750, 1050)\n",
    "ax.set_ylim(-0.15, 0.15)\n",
    "lm_mlp_outs_df.plot(ax=ax);\n",
    "ax.plot(lm_mlp_out_dfs[0]['expected'], alpha=0.3, linewidth=1, label='expected');\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-mlp-outs-all-test-comparison-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp_arch = '7-8-2-1'\n",
    "best_fcs_arch = '2-2-2-2-2-2-2'\n",
    "\n",
    "lm_rms_dfs = {\n",
    "    lm_mlp_architectures[best_mlp_arch]: pd.read_csv('final-outputs/cf-mlp-rms-all-{}.csv'.format(best_mlp_arch), index_col=None),\n",
    "    lm_fcs_architectures[best_fcs_arch]: pd.read_csv('final-outputs/cf-fcs-rms-all-{}.csv'.format(best_fcs_arch), index_col=None),\n",
    "}\n",
    "lm_out_dfs = {\n",
    "    lm_mlp_architectures[best_mlp_arch]: pd.read_csv('final-outputs/cf-mlp-outputs-all-{}.csv'.format(best_mlp_arch), index_col=None),\n",
    "    lm_fcs_architectures[best_fcs_arch]: pd.read_csv('final-outputs/cf-fcs-outputs-all-{}.csv'.format(best_fcs_arch), index_col=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de RMSE en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.05, 0.07)\n",
    "for architecture, df in lm_rms_dfs.items():\n",
    "    ax.plot(df['test'], label=architecture)\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-comparison-between-best-mlp-and-fcs-architecture-rms.pdf', bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximación al conjunto de test por las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximación al conjunto de error\n",
    "lm_outs_df = pd.DataFrame()\n",
    "for architecture, df in lm_out_dfs.items():\n",
    "    lm_outs_df[architecture] = df['real']\n",
    "\n",
    "# Detail\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "#ax.set_xlim(300, 550)\n",
    "ax.set_xlim(750, 1050)\n",
    "ax.set_ylim(-0.15, 0.15)\n",
    "lm_outs_df.plot(ax=ax);\n",
    "ax.plot(df['expected'], alpha=0.3, linewidth=1, label='expected');\n",
    "fig.savefig('thesis-figures/comparison-between-best-mlp-and-fcs-architecture-acceleration-profile-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de cambio de carril"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El path a la nube de puntos de ejemplo que representaremos es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pointcloud_path = 'thesis-figures/data/example_pointcloud.csv'\n",
    "pc = PointCloud.load(example_pointcloud_path).transform(**{'rot_y': 3.1, 'rot_z': -3.1}).roi(25,-25, 25,-25, 25, -25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa de profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = pc.to_deepmap(h_range=(0, 360), v_range=(-7, 3), h_res=1, v_res=2).normalize(orig=[-25, 25], dest=[1, 0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.imshow(dm.matrix, cmap=plt.cm.Oranges, interpolation='gaussian')\n",
    "ax.set_axis_off()\n",
    "ax.set_facecolor(None)\n",
    "ax.set_aspect(20)\n",
    "fig.savefig('thesis-figures/deepness-map.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mirroring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal image\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_ylim(-15, 15)\n",
    "ax.set_zlim(-15, 15)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "ax.scatter(pc.points[:,1], pc.points[:,0], pc.points[:,2], s=1);\n",
    "fig.savefig('thesis-figures/base-pointcloud.png', bbox_inches='tight')\n",
    "# Mirror image\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_ylim(-15, 15)\n",
    "ax.set_zlim(-15, 15)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "mpc = pc.mirror(fix_x=True, fix_z=True)\n",
    "ax.scatter(mpc.points[:,1], mpc.points[:,0], mpc.points[:,2], s=1);\n",
    "fig.savefig('thesis-figures/mirrored-pointcloud.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal image\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_ylim(-15, 15)\n",
    "ax.set_zlim(-15, 15)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "spc1 = pc.shake(shift_x=0.05, shift_y=0.05, shift_z=0.05)\n",
    "ax.scatter(spc1.points[:,1], spc1.points[:,0], spc1.points[:,2], s=1);\n",
    "fig.savefig('thesis-figures/shaken-pointcloud-05.png', bbox_inches='tight')\n",
    "# Mirror image\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_ylim(-15, 15)\n",
    "ax.set_zlim(-15, 15)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "spc2 = pc.shake(shift_x=0.2, shift_y=0.2, shift_z=0.2)\n",
    "ax.scatter(spc2.points[:,1], spc2.points[:,0], spc2.points[:,2], s=1);\n",
    "fig.savefig('thesis-figures/shaken-pointcloud-2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_dataset_description = {\n",
    "    'subject': [],\n",
    "    'Size training': [],\n",
    "    'LC training': [],\n",
    "    'RC training': [],\n",
    "    'Size test': [],\n",
    "    'LC test': [],\n",
    "    'RC test': [],\n",
    "}\n",
    "#for subject, code in SUBJECTS.items():\n",
    "#    # Training\n",
    "#    df = pd.read_csv('data/lc-{}-training.csv'.format(subject), index_col=None, dtype=np.int8)\n",
    "#    lc_dataset_description['subject'].append(code)\n",
    "#    lc_dataset_description['Size training'].append(len(df))\n",
    "#    lc_dataset_description['LC training'].append(len(df.loc[(np.isclose(df['Lane change left'], 1))]))\n",
    "#    lc_dataset_description['RC training'].append(len(df.loc[(np.isclose(df['Lane change right'], 1))]))\n",
    "#    \n",
    "#    # Test\n",
    "#    df = pd.read_csv('data/lc-{}-validation.csv'.format(subject), index_col=None, dtype=np.int8)\n",
    "#    lc_dataset_description['Size test'].append(len(df))\n",
    "#    lc_dataset_description['LC test'].append(len(df.loc[(np.isclose(df['Lane change left'], 1))]))\n",
    "#    lc_dataset_description['RC test'].append(len(df.loc[(np.isclose(df['Lane change right'], 1))]))\n",
    "#lc_dataset_description = pd.DataFrame(lc_dataset_description)\n",
    "#lc_dataset_description[['Size training', 'Size test', 'LC training', 'RC training', 'LC test', 'RC test']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_mlp_rms_f_pat = 'final-outputs/lc-mlp-accuracy-all-*.csv'\n",
    "lc_mlp_out_f_pat = 'final-outputs/lc-mlp-outputs-all-*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_mlp_acc_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_mlp_rms_f_pat), key=lambda x: (len(x), x))\n",
    "]\n",
    "lc_mlp_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_mlp_out_f_pat), key=lambda x: (len(x), x))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, sacamos los nombres de las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_mlp_architectures = {\n",
    "    s.replace('.csv', '').replace(lc_mlp_rms_f_pat[:-5], ''): '$MLP_{}$'.format(i)\n",
    "    for i, s in enumerate(sorted(glob.glob(lc_mlp_rms_f_pat), key=lambda x: (len(x), x)), start=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'architecture':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "}\n",
    "for i, (architecture, df) in enumerate(zip(lc_mlp_architectures, lc_mlp_acc_dfs)):\n",
    "    table['architecture'].append(lc_mlp_architectures[architecture])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "df = pd.DataFrame(table, index=None)\n",
    "df.set_index('architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión en training, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.2, 0.4)\n",
    "stage_df = pd.DataFrame()\n",
    "lines_training = []\n",
    "lines_validation = []\n",
    "for i, (architecture, df) in enumerate(zip(lc_mlp_architectures, lc_mlp_acc_dfs)):\n",
    "    lines_training += ax.plot(df['training'], label=lc_mlp_architectures[architecture], color='C{}'.format(i))\n",
    "    lines_validation += ax.plot(df['validation'], color='C{}'.format(i), alpha=0.3)\n",
    "ax.legend(handles=lines_training, loc=3)\n",
    "fig.savefig('thesis-figures/lc-mlp-acc-all-training-and-validation-detail.pdf', bbox_inches='tight')\n",
    "\n",
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.2, 0.4)\n",
    "for i, (architecture, df) in enumerate(zip(lc_mlp_architectures, lc_mlp_acc_dfs)):\n",
    "    lines_training += ax.plot(df['test'], label=lc_mlp_architectures[architecture], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels(), loc=3)\n",
    "fig.savefig('thesis-figures/lc-mlp-acc-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de estos resoltados, ya no se hace nada con MLP para cambio de carril"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes de convolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_cnn_rms_f_pat = 'final-outputs/lc-cnn-accuracy-all-*.csv'\n",
    "lc_cnn_out_f_pat = 'final-outputs/lc-cnn-outputs-all-*.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_cnn_acc_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_cnn_rms_f_pat), key=lambda x: (len(x), x))\n",
    "]\n",
    "lc_cnn_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_cnn_out_f_pat), key=lambda x: (len(x), x))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, sacamos los nombres de las arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_cnn_architectures = {\n",
    "    s.replace('.csv', '').replace(lc_cnn_rms_f_pat[:-5], ''): '$CNN_{}$'.format(i)\n",
    "    for i, s in enumerate(sorted(glob.glob(lc_cnn_rms_f_pat), key=lambda x: (len(x), x)), start=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'architecture':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "    'topology':[]\n",
    "}\n",
    "for i, (architecture, df) in enumerate(zip(lc_cnn_architectures, lc_cnn_acc_dfs)):\n",
    "    table['architecture'].append(lc_cnn_architectures[architecture])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "    table['topology'].append(architecture)\n",
    "df = pd.DataFrame(table, index=None)[['architecture', 'training', 'validation', 'test', 'topology']]\n",
    "df.set_index('architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión en training, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0, 0.65)\n",
    "stage_df = pd.DataFrame()\n",
    "lines_training = []\n",
    "lines_validation = []\n",
    "for i, (architecture, df) in enumerate(zip(lc_cnn_architectures, lc_cnn_acc_dfs)):\n",
    "    lines_training += ax.plot(df['training'], label=lc_cnn_architectures[architecture], color='C{}'.format(i))\n",
    "    lines_validation += ax.plot(df['validation'], color='C{}'.format(i), alpha=0.3)\n",
    "ax.legend(handles=lines_training, loc=3)\n",
    "fig.savefig('thesis-figures/lc-cnn-acc-all-training-and-validation-detail.pdf', bbox_inches='tight')\n",
    "\n",
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0, 0.65)\n",
    "for i, (architecture, df) in enumerate(zip(lc_cnn_architectures, lc_cnn_acc_dfs)):\n",
    "    lines_training += ax.plot(df['test'], label=lc_cnn_architectures[architecture], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels(), loc=3)\n",
    "fig.savefig('thesis-figures/lc-cnn-acc-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquita para que se vea cómo evoluciona en nuestros experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LEARN_RATE = 0.001\n",
    "MAX_LEARN_RATE = 0.1\n",
    "DECAY_SPEED = 20000\n",
    "EPOCHS = 500000\n",
    "MINIBATCH_SIZE = 25000\n",
    "\n",
    "X = np.arange(EPOCHS)\n",
    "Y = MIN_LEARN_RATE + (MAX_LEARN_RATE - MIN_LEARN_RATE) * np.exp(-X / DECAY_SPEED)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_M)\n",
    "ax.set_xlim(0, X[-1])\n",
    "ax.set_ylim(MIN_LEARN_RATE, MAX_LEARN_RATE)\n",
    "ax.plot(X, Y, label=r'$\\alpha_i = \\alpha_{min} + (\\alpha_{max} - \\alpha_{min}) \\cdot e^\\frac{i}{\\alpha_d}$')\n",
    "ax.legend(*ax.get_legend_handles_labels());\n",
    "fig.savefig('thesis-figures/lc-learning-rate-decay.pdf', bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_architecture = 'c16-4-18-v-d128-d0.1'\n",
    "df = pd.read_csv('final-outputs/lc-cnn-outputs-all-{}.csv'.format(best_architecture), index_col=None)\n",
    "df.iloc[1,1] = 2\n",
    "\n",
    "matrix = confusion_matrix(df['Real classes'], df['Predicted'])\n",
    "matrix = matrix / np.sum(matrix) * 100\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "fig.tight_layout()\n",
    "plot_confusion_matrix(ax, matrix, ['Left', 'None', 'Right'])\n",
    "\n",
    "matrix = np.array([\n",
    "    [7.37, 0.50, 6.88],\n",
    "    [5.66, 45.80, 24.12],\n",
    "    [3.00, 0.24, 6.44],\n",
    "])\n",
    "fig, ax = plt.subplots(1, 1, figsize=SQUARED_2)\n",
    "fig.tight_layout()\n",
    "plot_confusion_matrix(ax, matrix, ['Left', 'None', 'Right'])\n",
    "fig.savefig('thesis-figures/lc-cnn-model-confussion-matrix.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos específicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_specific_rms_f_pat = 'final-outputs/cf-mlp-rms-*-7-8-2-1.csv'\n",
    "lm_specific_out_f_pat = 'final-outputs/cf-mlp-outputs*-7-8-2-1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_specific_rms_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_specific_rms_f_pat))\n",
    "]\n",
    "lm_specific_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lm_specific_out_f_pat))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último sacamos los sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_specific_subjects = {}\n",
    "for i, s in enumerate(sorted(glob.glob(lm_specific_rms_f_pat))):\n",
    "    subject = s.replace('-7-8-2-1.csv', '').replace(lm_specific_rms_f_pat[:-13], '')\n",
    "    name = '$S_A$' if subject == 'all' else '$S_{}$'.format(i)\n",
    "    lm_specific_subjects[subject] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'subject':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "}\n",
    "for i, (subject, df) in enumerate(zip(lm_specific_subjects, lm_specific_rms_dfs)):\n",
    "    table['subject'].append(lm_specific_subjects[subject])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "df = pd.DataFrame(table, index=None)[['subject', 'training', 'validation', 'test']]\n",
    "df.set_index('subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "ax.set_xlim(*EPOCHS_X_LIM)\n",
    "ax.set_ylim(0.055, 0.065)\n",
    "for i, (subject, df) in enumerate(zip(lm_specific_subjects, lm_specific_rms_dfs)):\n",
    "    lines_training += ax.plot(df['test'], label=lm_specific_subjects[subject], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lm-specific-rmse-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de cambio de carril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_arch = 'c16-4-18-v-d128-d0.1'\n",
    "lc_specific_acc_f_pat = 'final-outputs/lc-cnn-accuracy-*-{}.csv'.format(best_cnn_arch)\n",
    "lc_specific_out_f_pat = 'final-outputs/lc-cnn-outputs*-{}.csv'.format(best_cnn_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los datos de los ficheros a sus respectivos dataframes para trabajar con ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_specific_acc_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_specific_acc_f_pat))\n",
    "]\n",
    "lc_specific_out_dfs = [\n",
    "    pd.read_csv(f, index_col=None)\n",
    "    for f in sorted(glob.glob(lc_specific_out_f_pat))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último sacamos los sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_specific_subjects = SUBJECTS_WITH_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'subject':[],\n",
    "    'training':[],\n",
    "    'validation':[],\n",
    "    'test':[],\n",
    "}\n",
    "for i, (subject, df) in enumerate(zip(SUBJECTS_WITH_ALL.keys(), lc_specific_acc_dfs)):\n",
    "    table['subject'].append(SUBJECTS_WITH_ALL[subject])\n",
    "    table['training'].append(df['training'].iloc[-1])\n",
    "    table['validation'].append(df['validation'].iloc[-1])\n",
    "    table['test'].append(df['test'].iloc[-1])\n",
    "df = pd.DataFrame(table, index=None)[['subject', 'training', 'validation', 'test']]\n",
    "df.set_index('subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE en training, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de evolución de test\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "ax.set_xlim(*(EPOCHS_X_LIM))\n",
    "ax.set_ylim(0.2, 1)\n",
    "for i, (subject, df) in enumerate(zip(SUBJECTS_WITH_ALL.keys(), lc_specific_acc_dfs)):\n",
    "    ax.plot(df['test'], label=SUBJECTS_WITH_ALL[subject], color='C{}'.format(i))\n",
    "ax.legend(*ax.get_legend_handles_labels())\n",
    "fig.savefig('thesis-figures/lc-specific-rmse-all-test-detail.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de personalización de los modelos de conducción específicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En modelo longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, code in SUBJECTS.items():\n",
    "    lm_comparison_df = pd.read_csv('final-outputs/cf-subjects-{}.csv'.format(subject), index_col=None)\n",
    "    # Perfil de aceleración\n",
    "    fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "    ax.set_xlim(0, len(lm_comparison_df))\n",
    "    ax.set_ylim(-0.2, 0.2)\n",
    "    for s, c in SUBJECTS.items():\n",
    "        lm_comparison_df[s].plot(ax=ax, label=c);\n",
    "    ax.plot(lm_comparison_df['expected'], alpha=0.3, linewidth=1, label=code + ' (real)');\n",
    "    ax.legend(*ax.get_legend_handles_labels())\n",
    "    fig.savefig('thesis-figures/lm-subjects-comparison-with-{}-acceleration-profiles.pdf'.format(subject), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, code in SUBJECTS.items():\n",
    "    lm_comparison_df = pd.read_csv('final-outputs/cf-subjects-{}.csv'.format(subject), index_col=None)\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            'subject': [code],\n",
    "            SUBJECTS['edgar']: [np.sqrt(mean_squared_error(lm_comparison_df['expected'], lm_comparison_df['edgar']))],\n",
    "            SUBJECTS['jj']: [np.sqrt(mean_squared_error(lm_comparison_df['expected'], lm_comparison_df['jj']))],\n",
    "            SUBJECTS['miguel']: [np.sqrt(mean_squared_error(lm_comparison_df['expected'], lm_comparison_df['miguel']))],\n",
    "        },\n",
    "        index=None\n",
    "    )\n",
    "    df.set_index('subject')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En cambio de carril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {\n",
    "    'Lane change left edgar': 0,\n",
    "    'Lane change none edgar': 1,\n",
    "    'Lane change right edgar': 2,\n",
    "    'Lane change left miguel': 0,\n",
    "    'Lane change none miguel': 1,\n",
    "    'Lane change right miguel': 2,\n",
    "    'Lane change left jj': 0,\n",
    "    'Lane change none jj': 1,\n",
    "    'Lane change right jj': 2,\n",
    "    'Lane change left': 0,\n",
    "    'Lane change none': 1,\n",
    "    'Lane change right': 2,\n",
    "}\n",
    "\n",
    "data = {}\n",
    "for subject, code in SUBJECTS.items():\n",
    "    lc_comparison_df = pd.read_csv('final-outputs/lc-subjects-{}.csv'.format(subject), index_col=None)\n",
    "    lc_comparison_df['expected'] = lc_comparison_df[['Lane change left', 'Lane change none', 'Lane change right']].idxmax(axis=1).apply(lambda x: MAP[x])\n",
    "    lc_comparison_df['edgar'] = lc_comparison_df[[c for c in lc_comparison_df.columns if c.endswith('edgar')]].idxmax(axis=1).apply(lambda x: MAP[x])\n",
    "    lc_comparison_df['jj'] = lc_comparison_df[[c for c in lc_comparison_df.columns if c.endswith('jj')]].idxmax(axis=1).apply(lambda x: MAP[x])\n",
    "    lc_comparison_df['miguel'] = lc_comparison_df[[c for c in lc_comparison_df.columns if c.endswith('miguel')]].idxmax(axis=1).apply(lambda x: MAP[x])\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            'subject': [code],\n",
    "            SUBJECTS['edgar']: [accuracy_score(lc_comparison_df['expected'], lc_comparison_df['edgar'])],\n",
    "            SUBJECTS['jj']: [accuracy_score(lc_comparison_df['expected'], lc_comparison_df['jj'])],\n",
    "            SUBJECTS['miguel']: [accuracy_score(lc_comparison_df['expected'], lc_comparison_df['miguel'])],\n",
    "        },\n",
    "        index=None\n",
    "    )\n",
    "    df.set_index('subject')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación en simulador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte es más costosa computacionalmente porque tiene que trabajar con los conjuntos de datos y los de cambio de carril son tochérrimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = pd.DataFrame(\n",
    "    None,\n",
    "    index=pd.MultiIndex.from_product(\n",
    "        [['V', 'AP', 'AN', 'JFF', 'JIF', 'JIM', 'JLC', 'LC', 'RC'], ['Real', 'Sim']],\n",
    "        names=['Indicador', 'Entorno']\n",
    "    ),\n",
    "    columns=['$S_A$ ($\\mu$)', '$S_A$ ($\\sigma$)', '$S_1$ ($\\mu$)', '$S_1$ ($\\sigma$)', '$S_2$ ($\\mu$)', '$S_2$ ($\\sigma$)', '$S_3$ ($\\mu$)', '$S_3$ ($\\sigma$)']\n",
    ")\n",
    "\n",
    "for subject, code in SUBJECTS_WITH_ALL.items():\n",
    "    # Datos de modelo longitudinal (reales)\n",
    "    df = pd.read_csv('data/cf-{}-validation.csv'.format(subject), index_col=None, dtype=np.float32)\n",
    "    # Speed\n",
    "    real_data_df.loc[('V', 'Real'),'{} ($\\mu$)'.format(code)] = df['Speed'].mean()\n",
    "    real_data_df.loc[('V', 'Real'),'{} ($\\sigma$)'.format(code)] = df['Speed'].std()\n",
    "    # Acceleration\n",
    "    real_data_df.loc[('AP', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[df['Acceleration'] > 0]['Acceleration'].mean()\n",
    "    real_data_df.loc[('AP', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[df['Acceleration'] > 0]['Acceleration'].std()\n",
    "    real_data_df.loc[('AN', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[df['Acceleration'] < 0]['Acceleration'].mean()\n",
    "    real_data_df.loc[('AN', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[df['Acceleration'] < 0]['Acceleration'].std()\n",
    "    # Jerk\n",
    "    df['Jerk'] = (df['Acceleration'].shift(-1) - df['Acceleration'])[:-1]\n",
    "    real_data_df.loc[('JIM', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['Acceleration'] > 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JIM', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['Acceleration'] > 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JLC', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['Acceleration'] < 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JLC', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['Acceleration'] < 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JIF', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['Acceleration'] < 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JIF', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['Acceleration'] < 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JFF', 'Real'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['Acceleration'] > 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JFF', 'Real'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['Acceleration'] > 0)]['Jerk'].std()\n",
    "\n",
    "    # Datos de cambio de carril (reales)\n",
    "    df = pd.read_csv('data/lc-{}-validation.csv'.format(subject), index_col=None, dtype=np.float32)\n",
    "    real_data_df.loc[('LC', 'Real'),'{} ($\\mu$)'.format(code)] = len(df.loc[(np.isclose(df['Lane change left'], 1))]) // 10\n",
    "    real_data_df.loc[('RC', 'Real'),'{} ($\\mu$)'.format(code)] = len(df.loc[(np.isclose(df['Lane change right'], 1))]) // 10\n",
    "\n",
    "    # Datos de modelo longitudinal (simulados)\n",
    "    df = pd.read_csv('final-outputs/cf-mlp-outputs-{}-7-8-2-1.csv'.format(subject), index_col=None, dtype=np.float32)\n",
    "    # Acceleration\n",
    "    real_data_df.loc[('AP', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[df['real'] > 0]['real'].mean()\n",
    "    real_data_df.loc[('AP', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[df['real'] > 0]['real'].std()\n",
    "    real_data_df.loc[('AN', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[df['real'] < 0]['real'].mean()\n",
    "    real_data_df.loc[('AN', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[df['real'] < 0]['real'].std()\n",
    "    # Jerk\n",
    "    df['Jerk'] = (df['real'].shift(-1) - df['real'])[:-1]\n",
    "    real_data_df.loc[('JIM', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['real'] > 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JIM', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['real'] > 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JLC', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['real'] < 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JLC', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] > 0) & (df['real'] < 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JIF', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['real'] < 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JIF', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['real'] < 0)]['Jerk'].std()\n",
    "    real_data_df.loc[('JFF', 'Sim'),'{} ($\\mu$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['real'] > 0)]['Jerk'].mean()\n",
    "    real_data_df.loc[('JFF', 'Sim'),'{} ($\\sigma$)'.format(code)] = df.loc[(df['Jerk'] < 0) & (df['real'] > 0)]['Jerk'].std()\n",
    "\n",
    "    # Datos de cambio de carril (reales)\n",
    "    df = pd.read_csv('final-outputs/lc-cnn-outputs-{}-c16-4-18-v-d128-d0.1.csv'.format(subject), index_col=None, dtype=np.float32)\n",
    "    real_data_df.loc[('LC', 'Sim'),'{} ($\\mu$)'.format(code)] = len(df.loc[(np.isclose(df['Predicted'], 1))]) // 100\n",
    "    real_data_df.loc[('RC', 'Sim'),'{} ($\\mu$)'.format(code)] = len(df.loc[(np.isclose(df['Predicted'], -1))]) // 100\n",
    "real_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de los modelos longitudinales (media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['AP', 'AN', 'JIM', 'JLC', 'JIF', 'JFF']\n",
    "lm_indicators_real_data_means = {\n",
    "    '$S_A$':[0.082, -0.088, 0.019, 0.032, -0.023, -0.035],\n",
    "    '$S_1$':[0.039, -0.087, 0.011, 0.019, -0.022, -0.021],\n",
    "    '$S_2$':[0.086, -0.080, 0.023, 0.039, -0.026, -0.045],\n",
    "    '$S_3$':[0.084, -0.110, 0.015, 0.016, -0.016, -0.018],\n",
    "}\n",
    "lm_indicators_simu_data_means = {\n",
    "    '$S_A$':[0.042, -0.050, 0.007, 0.009, -0.005, -0.012],\n",
    "    '$S_1$':[0.058, -0.053, 0.009, 0.012, -0.003, -0.034],\n",
    "    '$S_2$':[0.039, -0.039, 0.008, 0.010, -0.005, -0.011],\n",
    "    '$S_3$':[0.060, -0.065, 0.007, 0.010, -0.005, -0.013],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "markers = ['+', 'o', 'x', 'd']\n",
    "ax.set_ylim(-.15, .2)\n",
    "for i, (label, data) in enumerate(lm_indicators_real_data_means.items()):\n",
    "    ax.scatter(columns, data, alpha=1, label=label, color='C' + str(i), marker=markers[i]);\n",
    "for i, (_, data) in enumerate(lm_indicators_simu_data_means.items()):\n",
    "    ax.scatter(columns, data, alpha=.9, color='C' + str(i), marker=markers[i]);\n",
    "#ax.legend(loc='best', mode='expand', ncol=8);\n",
    "ax.legend(loc='best')\n",
    "fig.savefig('thesis-figures/lc-global-comparison-indicators-means.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de los modelos longitudinales (desviación típica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['AP', 'AN', 'JIM', 'JLC', 'JIF', 'JFF']\n",
    "lm_indicators_real_data_stds = {\n",
    "    '$S_A$':[0.042, 0.144, 0.084, 0.127, 0.060, 0.151],\n",
    "    '$S_1$':[0.029, 0.048, 0.011, 0.015, 0.019, 0.022],\n",
    "    '$S_2$':[0.260, 0.173, 0.112, 0.157, 0.074, 0.191],\n",
    "    '$S_3$':[0.040, 0.041, 0.013, 0.016, 0.014, 0.027],\n",
    "}\n",
    "lm_indicators_simu_data_stds = {\n",
    "    '$S_A$':[0.019, 0.034, 0.009, 0.018, 0.010, 0.023],\n",
    "    '$S_1$':[0.029, 0.043, 0.020, 0.024, 0.010, 0.047],\n",
    "    '$S_2$':[0.021, 0.024, 0.011, 0.019, 0.008, 0.188],\n",
    "    '$S_3$':[0.035, 0.038, 0.011, 0.017, 0.013, 0.027],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=WIDE_1)\n",
    "markers = ['+', 'o', 'x', 'd']\n",
    "for i, (label, data) in enumerate(lm_indicators_real_data_stds.items()):\n",
    "    ax.scatter(columns, data, alpha=1, label=label, color='C' + str(i), marker=markers[i]);\n",
    "for i, (_, data) in enumerate(lm_indicators_simu_data_stds.items()):\n",
    "    ax.scatter(columns, data, alpha=1, color='C' + str(i), marker=markers[i]);\n",
    "#ax.legend(loc='best', mode='expand', ncol=8);\n",
    "ax.legend(loc='best')\n",
    "fig.savefig('thesis-figures/lc-global-comparison-indicators-stds.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndices: Ajuste de controlador difuso basado en descenso del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La definición del controlador es la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzle.controller\n",
    "import fuzzle.defuzz\n",
    "import fuzzle.lvars\n",
    "import fuzzle.mfs\n",
    "import fuzzle.operators\n",
    "import fuzzle.rules\n",
    "\n",
    "fz_service = fuzzle.lvars.InputLVar('service', (0, 10))\n",
    "fz_service['bad'] = fuzzle.mfs.LineDescMF(5, 6)\n",
    "fz_service['average'] = fuzzle.mfs.TrapMF(5, 6, 7, 9)\n",
    "fz_service['good'] = fuzzle.mfs.LineAscMF(7, 9)\n",
    "\n",
    "fz_food = fuzzle.lvars.InputLVar('food', (0, 10))\n",
    "fz_food['bad'] = fuzzle.mfs.LineDescMF(5, 8)\n",
    "fz_food['average'] = fuzzle.mfs.TriMF(5, 8, 9)\n",
    "fz_food['good'] = fuzzle.mfs.LineAscMF(8, 9)\n",
    "\n",
    "fz_tip = fuzzle.lvars.OutputLVar('tip', domain=(0, 25), defuzz=fuzzle.defuzz.CoGS())\n",
    "fz_tip['low'] = fuzzle.mfs.SingletonMF(0)\n",
    "fz_tip['high'] = fuzzle.mfs.SingletonMF(25)\n",
    "\n",
    "rule_block = fuzzle.rules.RuleBlock(\n",
    "    and_op=fuzzle.operators.Minimum(),\n",
    "    or_op=fuzzle.operators.Maximum(),\n",
    "    not_op=fuzzle.operators.Zadeh(),\n",
    "    agg_op=fuzzle.operators.Minimum(),\n",
    "    acc_op=fuzzle.operators.Maximum()\n",
    ")\n",
    "rule_block[1] = 'IF service IS good THEN tip IS high'\n",
    "rule_block[2] = 'IF food IS good THEN tip IS high'\n",
    "rule_block[3] = 'IF service IS good AND food IS average THEN tip IS low'\n",
    "rule_block[4] = 'IF service IS average AND food IS good THEN tip IS high'\n",
    "rule_block[5] = 'IF service IS bad THEN tip IS low'\n",
    "rule_block[6] = 'IF food IS bad THEN tip IS low'\n",
    "\n",
    "inputs = [fz_service, fz_food]\n",
    "outputs = [fz_tip]\n",
    "\n",
    "fcs = fuzzle.controller.FuzzyController(inputs, outputs, rule_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particiones difusas del controlador real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in inputs:\n",
    "    mf_names = [fs for fs in var]\n",
    "    X = np.linspace(*var.domain, 1000)\n",
    "    Y = np.array([\n",
    "        [var[mf_name](x) for mf_name in mf_names]\n",
    "        for x in X\n",
    "    ])\n",
    "\n",
    "    # Plot the mfs\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    for i, (column, label) in enumerate(zip(Y.T, mf_names)):\n",
    "        ax.plot(X, column, alpha=1, label=label, color='C' + str(i));\n",
    "    ax.legend(loc='best');\n",
    "    fig.savefig('thesis-figures/real-tip-controller-var-{}.pdf'.format(var.name), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superficie del controlador real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = []\n",
    "for x in np.linspace(*fz_service.domain, 50):\n",
    "    for y in np.linspace(*fz_food.domain, 50):\n",
    "        controller_inputs = {fz_service.name: x, fz_food.name: y}\n",
    "        z = fcs.eval(controller_inputs)[fz_tip.name]\n",
    "        inferences.append((x, y, z))\n",
    "inferences = np.array(inferences)\n",
    "\n",
    "X, Y = np.meshgrid(np.unique(inferences[:,0]), np.unique(inferences[:,1]))\n",
    "Z = griddata(inferences[:,0], inferences[:,1], inferences[:,2], X, Y, interp='linear')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "fig.suptitle('Real tipping controller')\n",
    "ax.set_xlim(max(fz_service.domain), min(fz_service.domain))\n",
    "ax.set_ylim(min(fz_food.domain), max(fz_food.domain))\n",
    "ax.set_zlim(min(fz_tip.domain), max(fz_tip.domain))\n",
    "ax.set_xlabel(fz_service.name)\n",
    "ax.set_ylabel(fz_food.name)\n",
    "ax.set_zlabel(fz_tip.name)\n",
    "ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "fig.savefig('thesis-figures/real-tip-controller-surface.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste con controlador basado en descenso del gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos conjunto de datos aleatorios\n",
    "random_idx = np.random.randint(inferences.shape[0], size=50000)\n",
    "random_points = inferences[random_idx]\n",
    "np.save('thesis-figures/data/real-tip-controller-random-data', random_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Superficie del controlador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_points = np.load('thesis-figures/data/real-tip-controller-random-data.npy')\n",
    "\n",
    "# Creamos el controlador y lo ajustamos\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50000\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "service = tfz.IVar(name='service', fuzzy_sets=3, domain=(0, 10))\n",
    "food = tfz.IVar(name='food', fuzzy_sets=3, domain=(0, 10))\n",
    "tip = tfz.OVar(name='tip', values=(0, 25))\n",
    "\n",
    "x, ŷ = tfz.fuzzy_controller(\n",
    "    i_vars=[service, food],\n",
    "    o_var=tip\n",
    ")\n",
    "y = tf.placeholder(tf.float32)\n",
    "cost = tf.sqrt(tf.reduce_mean(tf.squared_difference(y, ŷ)))\n",
    "train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)\n",
    "\n",
    "inputs = random_points[:,:2]\n",
    "output = random_points[:,2][:,None]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    fig.suptitle('Adjusted tipping controller (init)')\n",
    "    ax.set_xlim(max(fz_service.domain), min(fz_service.domain))\n",
    "    ax.set_ylim(min(fz_food.domain), max(fz_food.domain))\n",
    "    ax.set_zlim(min(fz_tip.domain), max(fz_tip.domain))\n",
    "    ax.set_xlabel(fz_service.name)\n",
    "    ax.set_ylabel(fz_food.name)\n",
    "    ax.set_zlabel(fz_tip.name)\n",
    "    inference_result = session.run(ŷ, feed_dict={x: inferences[:,:2]})\n",
    "    X, Y = np.meshgrid(np.unique(inferences[:,0]), np.unique(inferences[:,1]))\n",
    "    Z = griddata(inferences[:,0], inferences[:,1], inference_result.flatten(), X, Y, interp='linear')\n",
    "    ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "    \n",
    "    fig.savefig('thesis-figures/ajusted-tip-controller-at-init-training.pdf', bbox_inches='tight')\n",
    "\n",
    "    feed_dict = {x: inputs, y: output}\n",
    "    rmss = [session.run(cost, feed_dict={x: inferences[:,:2], y: inferences[:,2][:,None]})]\n",
    "    for step in range(EPOCHS):\n",
    "        session.run(train, feed_dict=feed_dict)\n",
    "\n",
    "        if step == 1000:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            fig.suptitle('Adjusted tipping controller (after {} epochs)'.format(step))\n",
    "            ax.set_xlim(max(fz_service.domain), min(fz_service.domain))\n",
    "            ax.set_ylim(min(fz_food.domain), max(fz_food.domain))\n",
    "            ax.set_zlim(min(fz_tip.domain), max(fz_tip.domain))\n",
    "            ax.set_xlabel(fz_service.name)\n",
    "            ax.set_ylabel(fz_food.name)\n",
    "            ax.set_zlabel(fz_tip.name)    \n",
    "            inference_result = session.run(ŷ, feed_dict={x: inferences[:,:2]})\n",
    "            X, Y = np.meshgrid(np.unique(inferences[:,0]), np.unique(inferences[:,1]))\n",
    "            Z = griddata(inferences[:,0], inferences[:,1], inference_result.flatten(), X, Y, interp='linear')\n",
    "            ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "            fig.savefig('thesis-figures/ajusted-tip-controller-at-half-training.pdf', bbox_inches='tight')\n",
    "        rmss.append(session.run(cost, feed_dict={x: inferences[:,:2], y: inferences[:,2][:,None]}))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    fig.suptitle('Adjusted tipping controller (end)')\n",
    "    ax.set_xlim(max(fz_service.domain), min(fz_service.domain))\n",
    "    ax.set_ylim(min(fz_food.domain), max(fz_food.domain))\n",
    "    ax.set_zlim(min(fz_tip.domain), max(fz_tip.domain))\n",
    "    ax.set_xlabel(fz_service.name)\n",
    "    ax.set_ylabel(fz_food.name)\n",
    "    ax.set_zlabel(fz_tip.name)\n",
    "    inference_result = session.run(ŷ, feed_dict={x: inferences[:,:2]})\n",
    "    X, Y = np.meshgrid(np.unique(inferences[:,0]), np.unique(inferences[:,1]))\n",
    "    Z = griddata(inferences[:,0], inferences[:,1], inference_result.flatten(), X, Y, interp='linear')\n",
    "    ax.plot_surface(X, Y, Z, cmap=CMAP);\n",
    "    fig.savefig('thesis-figures/ajusted-tip-controller-at-end-training.pdf', bbox_inches='tight')\n",
    "\n",
    "# Impresión del RMS a lo largo del entrenamiento\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title('RMS during training')\n",
    "ax.plot(rmss)\n",
    "fig.savefig('thesis-figures/fcs-ajustment-rms-during-training.pdf', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
