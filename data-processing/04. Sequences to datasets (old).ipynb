{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se generar√°n los dataset para entrenar los modelos longitudinal y de cambio de carril."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os, glob\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pynsia.pointcloud import Deepmap\n",
    "\n",
    "figsize = (8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PATH = '/media/blazaid/Saca/PhD/data/curated'\n",
    "DEST_PATH = '/media/blazaid/Saca/PhD/data/datasets'\n",
    "SUBJECTS = edgar, jj, miguel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_DIR = os.path.join(ORIG_PATH, 'deepmaps')\n",
    "CF = 'cf'\n",
    "LC = 'lc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-9d25706367a4>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-9d25706367a4>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print('\\tLoading {} dataset ... '.format(dataset), end='')\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def load_sequences(path, subjects):\n",
    "    sequences = {\n",
    "        CF: {'training': [], 'validation': []},\n",
    "        LC: {'training': [], 'validation': []},\n",
    "    }\n",
    "\n",
    "    for submodel in (CF, LC):\n",
    "        print('Loading data for {} model'.format(submodel))\n",
    "        sequences[submodel] = {}\n",
    "        for dataset in ('training', 'validation'):\n",
    "            print('\\tLoading {} dataset ... '.format(dataset), end='')\n",
    "            sequences[submodel][dataset] = []\n",
    "            for subject in subjects:\n",
    "                file_pattern = '{}_{}_{}_*.csv'.format(submodel, subject, dataset)\n",
    "                sequences[submodel][dataset].extend([\n",
    "                    pd.read_csv(path, index_col=None)\n",
    "                    for path in glob.glob(os.path.join(path, file_pattern))\n",
    "                ])\n",
    "            print('{} loaded'.format(len(sequences[submodel][dataset])))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sequences = load_sequences(ORIG_PATH, SUBJECTS)\n",
    "pprint(base_sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
