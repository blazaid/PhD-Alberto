{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os, glob\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pynsia.pointcloud import Deepmap\n",
    "\n",
    "figsize = (8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PATH = '/media/blazaid/Saca/Phd/data/curated'\n",
    "DEST_PATH = '/media/blazaid/Saca/Phd/data/datasets'\n",
    "DMS_DIR = 'deepmaps'\n",
    "SUBJECTS = 'edgar', 'jj', 'miguel'\n",
    "MOMENTS_BEFORE = [5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_DIR = os.path.join(ORIG_PATH, 'deepmaps')\n",
    "CF = 'cf'\n",
    "LC = 'lc'\n",
    "MOMENTS_BEFORE.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(path, subjects):\n",
    "    sequences = {}\n",
    "    for dataset in ('training', 'validation'):\n",
    "        print('{} dataset'.format(dataset))\n",
    "        sequences[dataset] = {}\n",
    "        for submodel in (CF, LC):\n",
    "            print('\\t{} model'.format(submodel))\n",
    "            sequences[dataset][submodel] = {}\n",
    "            for subject in subjects:\n",
    "                print('\\t\\tLoading data for subject {} .. '.format(subject), end='')\n",
    "                file_pattern = os.path.join(path, '{}_{}_{}_*.csv'.format(submodel, subject, dataset))\n",
    "                sequences[dataset][submodel][subject] = [\n",
    "                    pd.read_csv(filepath, index_col=None, engine='python')\n",
    "                    for filepath in glob.glob(file_pattern)\n",
    "                ]\n",
    "                print('{} loaded'.format(len(sequences[dataset][submodel][subject])))\n",
    "\n",
    "    for dataset in ('training', 'validation'):\n",
    "        for submodel in (LC, CF):\n",
    "            sequences[dataset][submodel]['all'] = []\n",
    "            for subject in subjects:\n",
    "                sequences[dataset][submodel]['all'].extend(sequences[dataset][submodel][subject])\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset\n",
      "\tcf model\n",
      "\t\tLoading data for subject edgar .. 10 loaded\n",
      "\t\tLoading data for subject jj .. 6 loaded\n",
      "\t\tLoading data for subject miguel .. 12 loaded\n",
      "\tlc model\n",
      "\t\tLoading data for subject edgar .. 1584 loaded\n",
      "\t\tLoading data for subject jj .. 1958 loaded\n",
      "\t\tLoading data for subject miguel .. 1914 loaded\n",
      "validation dataset\n",
      "\tcf model\n",
      "\t\tLoading data for subject edgar .. 3 loaded\n",
      "\t\tLoading data for subject jj .. 5 loaded\n",
      "\t\tLoading data for subject miguel .. 7 loaded\n",
      "\tlc model\n",
      "\t\tLoading data for subject edgar .. 484 loaded\n",
      "\t\tLoading data for subject jj .. 660 loaded\n",
      "\t\tLoading data for subject miguel .. 660 loaded\n"
     ]
    }
   ],
   "source": [
    "base_sequences = load_sequences(ORIG_PATH, SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DEST_PATH):\n",
    "    os.makedirs(DEST_PATH)\n",
    "if not os.path.isdir(os.path.join(DEST_PATH, DMS_DIR)):\n",
    "    os.makedirs(os.path.join(DEST_PATH, DMS_DIR))\n",
    "\n",
    "for filename in glob.glob(os.path.join(DEST_PATH, '*')):\n",
    "    if not os.path.isdir(filename):\n",
    "        os.remove(filename)\n",
    "for filename in glob.glob(os.path.join(DEST_PATH, DMS_DIR, '*')):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building datasets\n",
      "\tBuilding cf training dataset for moments all ...done\n",
      "\tSaving dataset cf-all-training-t-t5-t10-t20.csv ... done\n",
      "Building datasets\n",
      "\tBuilding cf training dataset for moments miguel ...done\n",
      "\tSaving dataset cf-miguel-training-t-t5-t10-t20.csv ... done\n",
      "Building datasets\n",
      "\tBuilding cf training dataset for moments jj ...done\n",
      "\tSaving dataset cf-jj-training-t-t5-t10-t20.csv ... done\n",
      "Building datasets\n",
      "\tBuilding cf training dataset for moments edgar ...done\n",
      "\tSaving dataset cf-edgar-training-t-t5-t10-t20.csv ... done\n",
      "Building datasets\n",
      "\tBuilding lc training dataset for moments all ...done\n",
      "\tSaving dataset lc-all-training-t-t5-t10-t20.csv ... done\n",
      "\tSaving deepmaps ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f123f0608c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                             shutil.copy(\n\u001b[1;32m     41\u001b[0m                                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEST_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                             )\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in base_sequences:\n",
    "    for submodel in base_sequences[dataset]:\n",
    "        for subject in base_sequences[dataset][submodel]:\n",
    "            print('Building datasets')\n",
    "            dfs = base_sequences[dataset][submodel][subject]\n",
    "            # And now, construct the dataset\n",
    "            print('\\tBuilding {} {} dataset for moments {} ...'.format(submodel, dataset, subject), end='')\n",
    "            moments_suffix = 't-' + '-'.join([] + ['t{}'.format(x) for x in MOMENTS_BEFORE])\n",
    "            filename = '{}-{}-{}-{}.csv'.format(submodel, subject, dataset, moments_suffix)\n",
    "            \n",
    "            if submodel == CF:\n",
    "                datasets = pd.concat(dfs, ignore_index=True) \n",
    "            else:\n",
    "                datasets = []\n",
    "                temporal_columns = ['Acceleration', 'Next TLS status', 'Deepmap', 'Relative speed']\n",
    "                for df in dfs:\n",
    "                    # Generate the dataframes with the shifted times\n",
    "                    subset = df\n",
    "                    for moment in MOMENTS_BEFORE:\n",
    "                        temp_df = df.shift(moment)\n",
    "                        \n",
    "                        suffix = ' t_{}'.format(moment)\n",
    "                        for column in temporal_columns:\n",
    "                            subset[column + suffix] = temp_df[column]\n",
    "                    subset = subset[max(MOMENTS_BEFORE):]\n",
    "                    datasets.append(subset)\n",
    "                \n",
    "                datasets = pd.concat(datasets, ignore_index=True)\n",
    "            \n",
    "            print('done')\n",
    "            print('\\tSaving dataset {} ... '.format(filename), end='')\n",
    "            datasets.to_csv(os.path.join(DEST_PATH, filename), index=False)\n",
    "            print('done')\n",
    "            if submodel == LC:\n",
    "                print('\\tSaving deepmaps ... ', end='')\n",
    "                dm_columns = [c for c in datasets.columns if c.startswith('Deepmap')]\n",
    "                for index, row in datasets.iterrows():\n",
    "                    for column in dm_columns:\n",
    "                        if not os.path.exists(os.path.join(DEST_PATH, row[column])):\n",
    "                            shutil.copy(\n",
    "                                os.path.join(ORIG_PATH, row[column]),\n",
    "                                os.path.join(DEST_PATH, DMS_DIR),\n",
    "                            )\n",
    "                print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
