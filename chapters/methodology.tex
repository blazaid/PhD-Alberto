\chapter{Metodología}
\label{ch:methodology}

\TODO{Esto lo saco del paper de modelling blablabla de lane execution. Lo pongo aquí porque lcreo que lo suyo es poner la metodologías entera aquí. Además el tema de instrumentación, los recorridos, etcétera esta bien que estén aquí englobados. Hay que tener cuidado de, si se pone una cronología, que sea cierta, es decir, primero lane execution, luego lane intention, ...}

Para entrenar, comparar y validar los diferentes modelos de aceptación de cambio de carril, se ha seguido el siguiente método. Se utiliza un vehículo instrumentado para registrar los datos de conducción, primero, para el reconocimiento de patrones de conducción para clasificar los controladores en dos subconjuntos y segundo, para la construcción de conjuntos de datos para el proceso de formación de modelos. En el segundo caso, un operador estará presente en el vehículo y le pedirá a los sujetos que realicen un cambio a la izquierda o a la derecha en diferentes situaciones (principalmente con y sin automóviles en el entorno) mientras se graban los datos. Esos eventos luego se registran como intención de cambio de carril porque los sujetos deben ejecutar el cambio de carril si es posible. De esta forma, garantizamos que cada ejecución de cambio de carril (o imposibilidad de ejecución) está directamente relacionada con una intención de cambio de carril.

Las secciones que siguen describen cómo se instrumenta el vehículo, y se obtienen datos, cómo se procesan a una representación adecuada para entrenar a los modelos y, finalmente, cómo se entrena a los modelos.

\section{Instrumentación del vehículo}

El vehiculo usado para el desarrollo de esta tesis es un Mitsubishi iMiEV (Figura~\ref{fig:instrumented-imiev}). Éste ha sido instrumentado con los siguientes dispositivos:

\begin{figure}
	\includegraphics{instrumented-imiev}
	\caption{The instrumented Mitsubishi iMiEV.}
	\label{fig:instrumented-imiev}
\end{figure}

\begin{itemize}
	\item \textbf{LiDAR}. \TODO{explicación de qué es un LiDAR. Algo cortito del estilo mide la distancia a través la diferencia entre la emisión de pulsos de luz y su reflejo en un sensor. A lo mejor queda bien en un sidenote}. El usado es un Velodyne VLP-16, un LiDAR circular de 16 canales verticales separados 2º, dando un FOV (-15, 15) grados de apertura vertical). Este dispositivo se conecta a la máquina a través del puerto ethernet y se usa para la obtención de información del entorno del conductor. El LiDAR está situado en el techo del vehículo orientando los (0, 0) grados en al dirección y sentido de éste y con el plano horizontal paralelo al suelo.
	\item \textbf{Keyboard}. \TODO{No sé si ponerlo, pero al menos habría que mencionarlo, aquí o más adelante en el apartado específico de la ejecución de cambio de carril. A lo mejor se podría disfracar como un "gestionador de eventos" o algo así y poner un mando o unos botones de recreativa, que eso siempre queda bien.} Un teclado común conectado a través del puerto usb para funcionar como detector de eventos.
	\item \textbf{CAN Bus}. \TODO{Explicar qué es el CAN Bus, y si es necesario, un poquitín su funcionamiento (aunque sea en un sidenote, así queda todo más completito.)}. El BUS del vehículo se conecta a través del puerto USB al ordenador \TODO{a lo mejor hay que explicar un poco más la conexión, el tipo de cable y tal}. Es usado para la extracción de la interacción del conductor con el vehículo.
	\item \textbf{GPS Receiver}. \TODO{A lo mejor este no es necesario ponerlo. Yo creo que se podría decir que se usa para obtener una segunda medida de velocidad y aceleración, así como para la localización espacial de subconjuntos de datos interesantes para su estudio.}
\end{itemize}

Todos los dispositivos se conectan a un ordenador con sistema operativo Ubuntu GNU/Linux sobre Intel i7-6400U CPU con 8GB de memoria RAM. El esquema del vehículo instrumentado se detalla en la Figura~\ref{fig:instrumented-imiev-schema}.

\begin{figure}
	\includegraphics{instrumented-imiev-schema}
	\caption{The instrumented vehicle schema.}
	\label{fig:instrumented-imiev-schema}
\end{figure}

Todos los dispositivos han sido, o bien configurados para una captura a 10Hz de frecuencia, o bien remuestreados a ésta. La tabla~\ref{tbl:data-obtained-from-instrumented-vehicle} resume los datos recogidos y su dominio.

\begin{table}[t]
	\caption[Resúmen de información extraída del vehículo instrumentado][1.5em]{Valores capturados por el vehículo instrumentado y sus dominios. Los valores de 0, 1 y 2 se corresponden con los cambios de carril, siendo 0 cambio a la izquierda, 1 no cambio y 2 a la derecha.}
	\label{tbl:data-obtained-from-instrumented-vehicle}
	\begin{tabular}{lll}
		\toprule
		Variable & Descripción & Dominio \\
		\midrule
		LiDAR & Coordenadas de todos los puntos capturados por el dispositivo. & $[-200m, 200m] \subset \mathbb{R}$ \\
		\bottomrule
	\end{tabular}
\end{table}

\section{Perfiles de conducción}

Para tener suficiente información con la que trabajar, se han usado datos pertenecientes a conjuntos de conductores con diferentes perfiles de conducción. Todos los sujetos empleados en el experimento tiene el mismo rango de edad y género.

Tras obtener sus datos en rutas de prueba preliminares en entorno urbano, los sujetos se separaron en dos conjuntos de conductores con perfiles de conducción diferentes tal y como se describe en~\cite{DiazAlvarez2014}. Los sujetos cuyos datos eran difícilmente caracterizables no fueron incluidos en ninguno de los conjuntos.

Los parámetros usados para la clasificación corresponden al promedio y las varianzas de los 7 indicadores (uno para la velocidad, dos para la aceleración y cuatro para los tirones) para un total de 14 indicadores. Los valores se han normalizado para resaltar la diferencia entre ambos perfiles de la siguiente manera:

\begin{itemize}
	\item \textbf{Velocidad}. Media normalizada en el intervalo $[0, 20]$ y varianza en el intervalo $[0, 400]$.
	\item \textbf{Aceleración} y \textbf{jerk}. Media y varianza en el intervalo $[0, 2]$.
\end{itemize}

Los valores brutos se representan en la Tabla~\ref{tbl:raw-indicators-from-drivers-profiles}. Sus perfiles se han extraído de los datos de GPS y CAN Bus como se describe en [1]. La figura muestra el perfil normalizado para los datos de los dos subconjuntos de controladores (llamados Sm y Se).

\begin{table}
	\caption[Indicadores de los datos extraídos de cada perfil]{Indicadores extraídos a partir de los datos de cada perfil de conducción.}
	\label{tbl:raw-indicators-from-drivers-profiles}
	\begin{tabular}{@{}lllll@{}}
		\toprule
		\multirow{2}{*}{Indicador} & \multicolumn{2}{c}{$S_m$} & \multicolumn{2}{c}{$S\_e$} \\
		& $\mu$ & $\sigma$ & $\mu$ & $\sigma$ \\ \midrule
		Speed & 17.75 & 349.31 & 17.96 & 307.25 \\
		Negative acceleration (NA) & 1.91 & 4.44 & 1.52 & 1.91 \\
		Positive acceleration (PA) & 1.73 & 3.68 & 1.37 & 1.87 \\
		Starting movement jerk (SMJ) & 1.66 & 3.50 & 1.20 & 1.69 \\
		Cruising track jerk (CTJ) & 1.61 & 2.34 & 1.21 & 0.99 \\
		Starting brake jerk (SBJ) & 1.60 & 2.20 & 1.18 & 1.49 \\
		Ending brake jerk (EBJ) & 1.59 & 2.40 & 1.30 & 2.00 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{figure}
	\centering
	\subfloat[]{\includegraphics[width=.47\textwidth]{raw-indicators-from-drivers-profiles-a}}\qquad
	\subfloat[]{\includegraphics[width=.47\textwidth]{raw-indicators-from-drivers-profiles-b}}
	\caption{Comparación de indicadores entre los diferentes perfiles de conducción.}
	\label{fig:raw-indicators-from-drivers-profiles}
\end{figure}

\section{Routes}

Para la captura de datos se prepararon dos rutas, $R_1$ para utilizar los datos extraídos como datos de entrenamiento de los modelos y $R_2$ como datos para el proceso de validación de los mismos. La Figura~\ref{fig:proposed-routes} muestra los mapas para éstas. Ambas son rutas urbanas con una duración de aproximadamente 20 minutos, con tramos de uno y dos carriles, y en las que las velocidades máximas permitidas oscilan entre los 20 y los 50 \si{\kilo\metre\per\hour}. Fueron realizadas entre las 11:00am y las 12:00pm en días laborables, permitiendo una circulación con suficientes vehículos para conducir, pero sin demasiados como para impedir la circulación.

\begin{figure}
	\centering
	\subfloat[]{\includegraphics[width=.45\textwidth]{route-1}}\qquad
	\subfloat[]{\includegraphics[width=.45\textwidth]{route-2}}
	\caption{Las dos rutas del experimento, (a) Ruta $R_1$ para entrenamiento y (b) Ruta $R_2$ para validación.}
	\label{fig:proposed-routes}
\end{figure}

Los sujetos realizaron la ruta primero para familiarizarse con el circuito. Posteriormente, las rutas fueron realizadas y los datos extraídos para el resto del proceso.

\section{Proceso de los datos}

Tras la captura, los datos fueron preprocesados antes de entrenar los modelos. Los datos de cada modelo fueron preprocesados de manera distinta, por lo que este proceso quedará descrito más adelante en las secciones dedicadas a éstos.

\subsection{Descripción de los conjuntos de datos}

The datasets are built upon the sequences described above, but we need a way to feed up our models with a sense of time. For this purpose, the inputs in the datasets will be created with one or more previous rows of the sequences they include to add this temporary sense to the model in the form of a sliding temporal window.

Throughout the document we will talk about the concept moment. We will say that the moment $t_i$ is the row of data that occurred $\frac{i}{10}$ seconds ago, and therefore $t_0$ is the data corresponding to the present moment. Figure~\ref{fig:explanation-of-data-frequency} shows a simplified schematic outlining this concept.

\begin{figure}
	\includegraphics{explanation-of-data-frequency}
	\caption{Given the row of data in time $t$, we define the moment $T_i$ as the row of data that occurred in time $t - \frac{i}{10}$ seconds.}
	\label{fig:explanation-of-data-frequency}
\end{figure}

We will define four datasets implementing different moments. All the datasets will have the same number of outputs (3 being change left, no change and change right) but a different number of inputs according to the temporal window. Table~\ref{tbl:data-sets-description} describes the datasets used during the first stage of the experiment. The datasets are named $dsi_t$ and $dsi_v$, correspond to the $i$-th dataset for the training and validation partition respectively, and all of them correspond to the profile $S_m$. The dataset named $dsE_v$ is a single validation dataset and corresponds to the profile $S_e$. The reason of having only one validation dataset for profile $S_e$ is due to the results obtained in stage 1 (see below in results section 5).

\begin{table}[t]
	\caption[Resúmen de información extraída del vehículo instrumentado][1.5em]{Descripción de los conjuntos de datos utilizados en los experimentos.}
	\label{tbl:data-sets-description}
	\begin{tabular}{llllllll}
		\toprule
		Name & left & no change & right & inputs & moments & size & profile \\
		\midrule
		$ds1_t$ & 9804 & 44376 & 9804 & 4322 & $t_5$ & 63984 & $S_m$ \\
		$ds1_v$ & 410 & 1016 & 410 & 4322 & $t_5$ & 63984 & $S_m$ \\
		$ds2_t$ & 8544 & 42408 & 8544 & 4322 & $t_{10}$ & 63984 & $S_m$ \\
		$ds2_v$ & 312 & 976 & 312 & 4322 & $t_{10}$ & 63984 & $S_m$ \\
		$ds3_t$ & 8544 & 42408 & 8544 & 6483 & $t_5, t_{10}$ & 63984 & $S_m$ \\
		$ds3_v$ & 312 & 976 & 312 & 6483 & $t_5, t_{10}$ & 63984 & $S_m$ \\
		$ds4_t$ & 6504 & 38800 & 6504 & 8644 & $t_5, t_{10}, t_{20}$ & 63984 & $S_m$ \\
		$ds4_v$ & 144 & 896 & 144 & 8644 & $t_5, t_{10}, t_{20}$ & 63984 & $S_m$ \\
		$dsE_v$ & 151 & 725 & 151 & 8644 & $t_5, t_{10}, t_{20}$ & 63984 & $S_m$ \\
		\bottomrule
	\end{tabular}
\end{table}

The choice of 5 and 10 frames (500ms and 1s according with the frequency of 10Hz) as key time points in the temporal windows is not arbitrary. Here we assume that the process of lane-change execution is a task that involves the visual cortex and the prefrontal cortex in the brain. Thus, we could assume that the response time is between 0.2s to 1.2s \cite{lipton2015critical}.

All the training and validations have been executed on a computer different from the one in the vehicle using the library TensorFlow [28] from Google. The operative system is a Debian GNU/Linux 9.1 (Stretch) over an Intel(R) Core(TM) i7-6700K CPU at 4.00GHz de 16GB of RAM and a nVidia TITAN X with 12GB of GDDR5X RAM and 3585 CUDA cores at 1.53GHz.
We have used the training method called Adam (Adaptive Momentum Estimator [29]), a very successful gradient descent algorithm which combines the idea of momentum with the RMSProp [30]. Adam algorithm relies in 4 parameters, , ,  and . The parameter  is associated to the momentum, while  is the one associated with RMSProp.   corresponds to a very small value to avoid divisions by zero and the last one, , is the learning rate. In our case, we will maintain the default parameters proposed in the paper for ,  and  (,  and  respectively) and set a learning rate  deduced by a trial and error process.
To avoid memory exhaustion problems and follow closely the evolution of the training processes, a minibatch of 1.000 items is implemented.
For the purposes of including the lane-change intention features in the CNN architectures, a modification over the general layout has been implemented. In it, the LIDAR images are presented to the network input whereas the lane-change intention features are normalized and presented to the dense layers right after all the pattern detection phase. That is the reason of the variation on the number of neurons. The intuition behind this decision is that, after all the pattern detection phase, it is expected to have some of them recognized right before the dense layers, i.e. the classification phase. We can consider lane-change intention features as already recognized patterns and thus it is not necessary to add a transformation of them into the pattern recognition phase. So, if there are N neurons specified in that layers and the dataset specifying M lane-change intention features, the dense layer is composed of  neurons.
To find the optimal architecture for this purpose, the training process is separated into two stages. In the first one (stage 1), a shallow analysis was performed over a superficial study on a wide range of architectures for all the training sets. Specifically, the training process has been performed over 135 ANNs (90 MLPs and 45CNNs as described in Error: no se encontró el origen de la referencia and Error: no se encontró el origen de la referencia respectively). The networks were trained during 10.000 epochs of 1.000 mini-batches and then validated for each of the proposed datasets (described in Table ).
In the second one (stage 2), a more in-depth study over the most interesting architectures for both families is performed, improving the deficiencies detected (as shown in the results section) and training the models until the validation error is stabilized.